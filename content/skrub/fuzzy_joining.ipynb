{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Fuzzy joining dirty tables with the Joiner\n",
        "\n",
        "Here we show how to combine data from different sources,\n",
        "with a vocabulary not well normalized.\n",
        "\n",
        "Joining is difficult: one entry on one side does not have\n",
        "an exact match on the other side.\n",
        "\n",
        "The ``fj`` function enables to join tables without cleaning the data by\n",
        "accounting for the label variations.\n",
        "\n",
        "To illustrate, we will join data from the\n",
        "[2022 World Happiness Report](https://worldhappiness.report/), with tables\n",
        "provided in [the World Bank open data platform](https://data.worldbank.org/)\n",
        "in order to create a first prediction model.\n",
        "\n",
        "Moreover, the ``joiner`` is a scikit-learn Transformer that makes it easy to\n",
        "use such fuzzy joining multiple tables to bring in information in a\n",
        "machine-learning pipeline. In particular, it enables tuning parameters of\n",
        "|fj| to find the matches that maximize prediction accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Importing and preprocessing\n",
        "\n",
        "We import the happiness score table first:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/skrub-data/datasets/master/data/Happiness_report_2022.csv\",  # noqa\n",
        "    thousands=\",\",\n",
        ")\n",
        "df.drop(df.tail(1).index, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the table:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a table that contains the happiness index of a country along with\n",
        "some of the possible explanatory factors: GDP per capita, Social support,\n",
        "Generosity etc.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of this example, we only keep the country names and our\n",
        "variable of interest: the 'Happiness score'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = df[[\"Country\", \"Happiness score\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional tables from other sources\n",
        "\n",
        "Now, we need to include explanatory factors from other sources, to\n",
        "complete our covariates (X table).\n",
        "\n",
        "Interesting tables can be found on [the World Bank open data platform](https://data.worldbank.org/), for which we have a downloading\n",
        "function:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub.datasets import fetch_world_bank_indicator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We extract the table containing GDP per capita by country:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gdppc = fetch_world_bank_indicator(indicator_id=\"NY.GDP.PCAP.CD\").X\n",
        "gdppc.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then another table, with life expectancy by country:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "life_exp = fetch_world_bank_indicator(\"SP.DYN.LE00.IN\").X\n",
        "life_exp.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And a table with legal rights strength by country:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "legal_rights = fetch_world_bank_indicator(\"IC.LGL.CRED.XQ\").X\n",
        "legal_rights.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A correspondence problem\n",
        "\n",
        "Alas, the entries for countries do not perfectly match between our\n",
        "original table (df), and those that we downloaded from the worldbank\n",
        "(gdppc):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=\"Country\").tail(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gdppc.sort_values(by=\"Country Name\").tail(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that Yemen is written \"Yemen*\" on one side, and\n",
        "\"Yemen, Rep.\" on the other.\n",
        "\n",
        "We also have entries that probably do not have correspondences: \"World\"\n",
        "on one side, whereas the other table only has country-level data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Joining tables with imperfect correspondence\n",
        "\n",
        "We will now join our initial table, df, with the 3 additional ones that\n",
        "we have extracted.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We will ignore the warnings:\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 1. Joining GDP per capita table\n",
        "\n",
        "To join them with skrub, we only need to do the following:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub import fuzzy_join\n",
        "\n",
        "df1 = fuzzy_join(\n",
        "    df,  # our table to join\n",
        "    gdppc,  # the table to join with\n",
        "    left_on=\"Country\",  # the first join key column\n",
        "    right_on=\"Country Name\",  # the second join key column\n",
        "    return_score=True,\n",
        ")\n",
        "\n",
        "df1.tail(20)\n",
        "# We merged the first WB table to our initial one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. topic:: Note:\n",
        "\n",
        "   We fix the ``return_score`` parameter to `True` so as to keep the matching\n",
        "   score, that we will use later to show what are the worst matches.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that our |fj| succesfully identified the countries,\n",
        "even though some country names differ between tables.\n",
        "\n",
        "For instance, \"Czechia\" is well identified as \"Czech Republic\" and\n",
        "\"Luxembourg*\" as \"Luxembourg\".\n",
        "\n",
        ".. topic:: Note:\n",
        "\n",
        "   This would all be missed out if we were using other methods such as\n",
        "   [pandas.merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html),  # noqa\n",
        "   which can only find exact matches.\n",
        "   In this case, to reach the best result, we would have to `manually` clean\n",
        "   the data (e.g. remove the * after country name) and look\n",
        "   for matching patterns in every observation.\n",
        "\n",
        "Let's do some more inspection of the merging done.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's print the four worst matches, which will give\n",
        "us an overview of the situation:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df1.sort_values(\"matching_score\").head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that some matches were unsuccesful\n",
        "(e.g \"Palestinian Territories*\" and \"Palau\"),\n",
        "because there is simply no match in the two tables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, it is better to use the threshold parameter\n",
        "so as to include only precise-enough matches:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df1 = fuzzy_join(\n",
        "    df,\n",
        "    gdppc,\n",
        "    left_on=\"Country\",\n",
        "    right_on=\"Country Name\",\n",
        "    match_score=0.35,\n",
        "    return_score=True,\n",
        ")\n",
        "df1.sort_values(\"matching_score\").head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Matches that are not available (or precise enough) are marked as `NaN`.\n",
        "We will remove them using the drop_unmatched parameter:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df1 = fuzzy_join(\n",
        "    df,\n",
        "    gdppc,\n",
        "    left_on=\"Country\",\n",
        "    right_on=\"Country Name\",\n",
        "    match_score=0.35,\n",
        "    drop_unmatched=True,\n",
        ")\n",
        "\n",
        "df1.drop(columns=[\"Country Name\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can finally plot and look at the link between GDP per capital\n",
        "and happiness:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_context(\"notebook\")\n",
        "\n",
        "plt.figure(figsize=(4, 3))\n",
        "ax = sns.regplot(\n",
        "    data=df1,\n",
        "    x=\"GDP per capita (current US$)\",\n",
        "    y=\"Happiness score\",\n",
        "    lowess=True,\n",
        ")\n",
        "ax.set_ylabel(\"Happiness index\")\n",
        "ax.set_title(\"Is a higher GDP per capita linked to happiness?\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that the happiest countries are those\n",
        "having a high GDP per capita.\n",
        "However, unhappy countries do not have only low levels\n",
        "of GDP per capita. We have to search for other patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Joining life expectancy table\n",
        "\n",
        "Now let's include other information that may be relevant, such as in the\n",
        "life_exp table:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df2 = fuzzy_join(\n",
        "    df1,\n",
        "    life_exp,\n",
        "    left_on=\"Country\",\n",
        "    right_on=\"Country Name\",\n",
        "    match_score=0.45,\n",
        ")\n",
        "\n",
        "df2.drop(columns=[\"Country Name\"], inplace=True)\n",
        "\n",
        "df2.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot this relation:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "fig = sns.regplot(\n",
        "    data=df2,\n",
        "    x=\"Life expectancy at birth, total (years)\",\n",
        "    y=\"Happiness score\",\n",
        "    lowess=True,\n",
        ")\n",
        "fig.set_ylabel(\"Happiness index\")\n",
        "fig.set_title(\"Is a higher life expectancy linked to happiness?\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems the answer is yes!\n",
        "Countries with higher life expectancy are also happier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Joining legal rights strength table\n",
        "\n",
        "And the table with a measure of legal rights strength in the country:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df3 = fuzzy_join(\n",
        "    df2,\n",
        "    legal_rights,\n",
        "    left_on=\"Country\",\n",
        "    right_on=\"Country Name\",\n",
        "    match_score=0.45,\n",
        ")\n",
        "\n",
        "df3.drop(columns=[\"Country Name\"], inplace=True)\n",
        "\n",
        "df3.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at their correspondence in a figure:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "fig = sns.regplot(\n",
        "    data=df3,\n",
        "    x=\"Strength of legal rights index (0=weak to 12=strong)\",\n",
        "    y=\"Happiness score\",\n",
        "    lowess=True,\n",
        ")\n",
        "fig.set_ylabel(\"Happiness index\")\n",
        "fig.set_title(\"Does a country's legal rights strength lead to happiness?\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this plot, it is not clear that this measure of legal strength\n",
        "is linked to happiness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! Our joined table has become bigger and full of useful information.\n",
        "And now we are ready to apply a first machine learning model to it!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction model\n",
        "\n",
        "We now separate our covariates (X), from the target (or exogenous)\n",
        "variables: y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X = df3.drop(\"Happiness score\", axis=1).select_dtypes(exclude=object)\n",
        "y = df3[[\"Happiness score\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now define the model that will be used to predict the happiness score:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "hgdb = HistGradientBoostingRegressor(random_state=0)\n",
        "cv = KFold(n_splits=2, shuffle=True, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate our model, we will apply a `4-fold cross-validation`.\n",
        "We evaluate our model using the `R2` score.\n",
        "\n",
        "Let's finally assess the results of our models:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "cv_results_t = cross_validate(hgdb, X, y, cv=cv, scoring=\"r2\")\n",
        "\n",
        "cv_r2_t = cv_results_t[\"test_score\"]\n",
        "\n",
        "print(f\"Mean R2 score is {cv_r2_t.mean():.2f} +- {cv_r2_t.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a satisfying first result: an R2 of 0.66!\n",
        "\n",
        "Data cleaning varies from dataset to dataset: there are as\n",
        "many ways to clean a table as there are errors. |fj|\n",
        "method is generalizable across all datasets.\n",
        "\n",
        "Data transformation is also often very costly in both time and ressources.\n",
        "|fj| is fast and easy-to-use.\n",
        "\n",
        "Now up to you, try improving our model by adding information into it and\n",
        "beating our result!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the |joiner| to fuzzy join multiple tables\n",
        "A faster way to merge different tables from the World Bank\n",
        "to `X` is to use the |joiner|.\n",
        "\n",
        "The |joiner| is a transformer that can easily chain joins of tables on\n",
        "a main table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Instantiating the transformer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = df[\"Happiness score\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We gather the auxilliary tables into a\n",
        "list of (tables, keys) for the `tables` parameter.\n",
        "An instance of the transformer with the necessary information is:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub import Joiner\n",
        "\n",
        "joiner = Joiner(\n",
        "    tables=[\n",
        "        (gdppc, \"Country Name\"),\n",
        "        (life_exp, \"Country Name\"),\n",
        "        (legal_rights, \"Country Name\"),\n",
        "    ],\n",
        "    main_key=\"Country\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fitting and transforming into the final table\n",
        "To get our final joined table we will fit and transform the main table (df)\n",
        "with our create instance of the |joiner|:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_final = joiner.fit_transform(df)\n",
        "\n",
        "df_final.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it! As previously, we now have a big table\n",
        "ready for machine learning.\n",
        "Let's create our machine learning pipeline:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# We include only the columns that will be pertinent for our regression:\n",
        "encoder = make_column_transformer(\n",
        "    (\n",
        "        \"passthrough\",\n",
        "        [\n",
        "            \"GDP per capita (current US$)\",\n",
        "            \"Life expectancy at birth, total (years)\",\n",
        "            \"Strength of legal rights index (0=weak to 12=strong)\",\n",
        "        ],\n",
        "    ),\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(joiner, encoder, HistGradientBoostingRegressor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the best part is that we are now able to evaluate the parameters of the |fj|.\n",
        "For instance, the ``match_score`` was manually picked and can now be\n",
        "introduced into a grid search:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# We will test four possible values of match_score:\n",
        "params = {\"joiner__match_score\": [0.2, 0.3, 0.4, 0.5]}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid=params)\n",
        "grid.fit(df, y)\n",
        "\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The grid searching gave us the best value of 0.5 for the parameter\n",
        "``match_score``. Let's use this value in our regression:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Mean R2 score with pipeline is {grid.score(df, y):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. topic:: Note:\n",
        "\n",
        "   Here, ``grid.score()`` takes directly the best model\n",
        "   (with ``match_score=0.5``) that was found during the grid search.\n",
        "   Thus, it is equivalent to fixing the ``match_score`` to 0.5 and\n",
        "   refitting the pipeline on the data.\n",
        "\n",
        "\n",
        "Great, by evaluating the correct ``match_score`` we improved our\n",
        "results significantly!\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
